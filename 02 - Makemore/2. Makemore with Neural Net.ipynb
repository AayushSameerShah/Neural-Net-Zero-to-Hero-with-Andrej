{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a16b513-1e9e-4455-9acb-36dcab7bc63c",
   "metadata": {},
   "source": [
    "# How was the experience!?\n",
    "Finally we have made our first steps into the generation field! There still is the ocean needs to be sailed, so hold on, don't fear, let's keep going.\n",
    "\n",
    "So, as discussed in the previous notebook, we have ***counted*** the character bigrams manually, so that is something we will call the \"trained\" model and with that static info in mind, at hand, we have tried to generate the **new** names.\n",
    "\n",
    "**Now**, we want to do the same - but we will use the neural net ***to learn those counts*** instead of providing the counts manually *(so a bit more towards deep \"learning\")*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81ff96a-46b9-49eb-8123-dc6c7efd624d",
   "metadata": {},
   "source": [
    "## The overview of the üß†\n",
    "\n",
    "    The input (like we did in previous) - a character \n",
    "        ‚Üí Neural Net\n",
    "            ‚Üí Distribution after that character\n",
    "                ‚Üí Predict the next word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd2170-2588-46c9-b38c-6861384d3174",
   "metadata": {},
   "source": [
    "> **Hands up üëê**: Before moving on, ***this*** time and from now on, we will use the `torch` library for doing all stuff. Please don't hate me doing this, because we are now building the neural nets mate! That simply would be to verbose with the numpy.\n",
    "\n",
    "So, for anything from random number generation to the neural net, we will use the torch. Whenever possible, I will provide the *\"alternative\"* code for the same in numpy, but for most of the part, we will use the torch. Sorry for that, because sooner or later we will need to use pytorch, because other libraries like Tensorflow are now the history and torch is the future *(to light in the darkness üòâ)*. Argh [clears throat], pardon me.\n",
    "\n",
    "*PS: Don't worry, we will use micrograd as well to see the comparison in learning between torch model and micrograd as bonus üéâ*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b78f1d2-1ae3-4ac9-bd07-53daec1c0215",
   "metadata": {},
   "source": [
    "### As a sum-up of the situation\n",
    "\n",
    "We have 2 ways to learn the relationships between the characters (to generate new ones)\n",
    "\n",
    "<pre>\n",
    "                                                                      \n",
    "                                                                      \n",
    "                                                                      \n",
    "                                                                      \n",
    "                   +-------------------+         +-------------------+\n",
    "                   |                   |         |                   |\n",
    "                   | Way 1             |         | Way 2             |\n",
    "                   |                   |         |                   |\n",
    "                   | Give a computer   |         | Let the computer  |\n",
    "                   | the set of rules  |         | find the rules    |\n",
    "                   | by finding them   |         | and use them for  |\n",
    "                   | manually          |         | the generation.   |\n",
    "                   |                   |         |                   |\n",
    "                   +--------|----------+         +--------|----------+\n",
    "                            |                             |           \n",
    "                            |                             |           \n",
    "                   +--------|----+                 +------|------+    \n",
    "                   |             |                 |             |    \n",
    "                   | The bigram  |                 |The bigram   |    \n",
    "                   | table given |                 |table learnt |    \n",
    "                   |             |                 |by NN        |    \n",
    "                   +-------|-----+                 +-------|-----+    \n",
    "                           |                               |          \n",
    "                           |                               |          \n",
    "                     Generate!                       Generate!        \n",
    "                     üíª: ...                         ü§ñ: ...          \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b757b261-3c32-4abc-aa57-10f1e430169c",
   "metadata": {},
   "source": [
    "Great, so now we are on the **way 2** and will learn the bigram table. *(of course, I am using the \"bigram table to learn\" phrase loosely. We don't learn the tables but the rules that generalize the relationship which infact are not in the form of the table, but the graph that spans across the millions, billions of parameters that the tables can never store.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbfdb3dd-7a6d-469a-b50c-f2c3ac064ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The usual imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## TORCH WILL BE IMPORTED LATER. LEGENDS HAVE THEIR OWN ENTERIES! ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1294598e-2b1b-4088-8f91-430429b6d408",
   "metadata": {},
   "source": [
    "üëâ As a refresher, here are our names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93ab637a-3377-4226-b771-fa3ae58c806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "with open(\"./names.txt\", \"r\") as file:\n",
    "    names = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aa33c77-e566-4cc3-b5b2-8ebe4084966e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbc60a1-d8cc-44a4-8bfb-def41e80f08c",
   "metadata": {},
   "source": [
    "If you are familiar with the \"ARIMA\" model, we basically ***make*** (again, ***make***) the dataset as a supervised learning dataset. These type of problems don't have the conventional labels to learn so we make them!\n",
    "\n",
    "So, in this NLG setting, we will \"predict\" the next character here, thus, for the past word `ch1` the next token to be predicted will be `ch2` so that `ch2` will be the \"label\" for the `ch1`. Then `ch3` will be the label for the `ch2` and it will continue for all words in the universe.\n",
    "___\n",
    "Here, for our names..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f4eb31f-0286-42ce-a4a3-32624e00eef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- emma ---\n",
      "< ‚Üí e\n",
      "e ‚Üí m\n",
      "m ‚Üí m\n",
      "m ‚Üí a\n",
      "a ‚Üí >\n",
      "\n",
      "--- olivia ---\n",
      "< ‚Üí o\n",
      "o ‚Üí l\n",
      "l ‚Üí i\n",
      "i ‚Üí v\n",
      "v ‚Üí i\n",
      "i ‚Üí a\n",
      "a ‚Üí >\n",
      "\n",
      "--- ava ---\n",
      "< ‚Üí a\n",
      "a ‚Üí v\n",
      "v ‚Üí a\n",
      "a ‚Üí >\n",
      "\n",
      "--- isabella ---\n",
      "< ‚Üí i\n",
      "i ‚Üí s\n",
      "s ‚Üí a\n",
      "a ‚Üí b\n",
      "b ‚Üí e\n",
      "e ‚Üí l\n",
      "l ‚Üí l\n",
      "l ‚Üí a\n",
      "a ‚Üí >\n",
      "\n",
      "--- sophia ---\n",
      "< ‚Üí s\n",
      "s ‚Üí o\n",
      "o ‚Üí p\n",
      "p ‚Üí h\n",
      "h ‚Üí i\n",
      "i ‚Üí a\n",
      "a ‚Üí >\n"
     ]
    }
   ],
   "source": [
    "# Our same loop will work!\n",
    "\n",
    "for name in names[:5]:\n",
    "    print(\"\\n---\", name, \"---\")\n",
    "    name = \"<\" + name + \">\"\n",
    "    for ch1, ch2 in zip(name, name[1:]):    \n",
    "        print(ch1, \"‚Üí\", ch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aba5bc5-67a0-43da-91fc-3bbb314730cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAKING THE DATASET ##\n",
    "\n",
    "xs = [] # The ch1 (previous character)\n",
    "ys = [] # The ch2 (next character to be predicted - lables)\n",
    "\n",
    "for name in names:\n",
    "    name = \"<\" + name + \">\"\n",
    "    for ch1, ch2 in zip(name, name[1:]):    \n",
    "        xs.append(ch1)\n",
    "        ys.append(ch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cacfed08-7881-48fc-b75f-cee1475ef608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228146"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5eb7250-1c2e-46ce-80ee-0c130f74c58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228146"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce4d50e1-4952-41ac-8edd-bc43c58c4f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<', 'e', 'm', 'm', 'a']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bcd2066-757a-42b8-ae6f-81a00529a1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'm', 'm', 'a', '>']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07db9a14-36d2-4475-9922-9a42c3202e06",
   "metadata": {},
   "source": [
    "Are you getting it mate!?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc1ed7-e820-48b4-81b1-5d62fd30086a",
   "metadata": {},
   "source": [
    "And, we will convert these into the tensors... because some famous pythonist once said:\n",
    "> \"Convert the data into the language that the NNs can understand, which are fast to operate through, <br>and lists are not the one of them.\" <br><br>‚Äî Unknown *(probably me)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "704c480e-a2d2-4ee3-b25d-cf084074f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for the CPU dependency ##\n",
    "# !pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c59f15ab-20fa-4780-bede-758a226afd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First time using the tensors\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "831b8ae9-0094-44db-a573-a53c91c5cff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<', 'e', 'm', 'm', 'a']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b77f5cbd-decc-4662-8491-bfdd440d924b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m xs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m ys \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(ys)\n",
      "\u001b[1;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de1a1d1-04bb-409a-9af9-f38f1dde58b7",
   "metadata": {},
   "source": [
    "# ü§Ø Oops!\n",
    "This has to happen. <br>\n",
    "**Because tensors** only understand the numerical values. But we are passing the string. So, to convert these into the numbers, we need the *mapping*. \n",
    "\n",
    "Sorry me, in the previous example of Makemore (and to simplify the process) we did not do such conversion from string to number. But now, we will need to. So let's quickly do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0556ed47-3829-454f-ae69-b0e5dca8f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will map `<` and `>` special tokens as 0 and 1, after that we will start with a, b, c...\n",
    "\n",
    "## For safety, we will only use the characters which are present in the dataset ##\n",
    "unique_characters = set()\n",
    "for name in names:\n",
    "    for ch in name:\n",
    "        unique_characters.add(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17a42e31-85f2-4df5-908b-2e75416b19b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<',\n",
       " '>',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_characters = ['<', '>'] + sorted(list(unique_characters))\n",
    "unique_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef937e3-a603-4cc5-b72c-c4038a51a06e",
   "metadata": {},
   "source": [
    "We cool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6b60f08-51a6-4d71-8eb3-381839c7b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_to_ch = {}\n",
    "ch_to_number = {}\n",
    "for idx, ch in enumerate(unique_characters):\n",
    "    number_to_ch[idx] = ch\n",
    "    ch_to_number[ch] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad8f99c7-8c92-4e68-a2f5-c48f3a3cfdd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<',\n",
       " 1: '>',\n",
       " 2: 'a',\n",
       " 3: 'b',\n",
       " 4: 'c',\n",
       " 5: 'd',\n",
       " 6: 'e',\n",
       " 7: 'f',\n",
       " 8: 'g',\n",
       " 9: 'h',\n",
       " 10: 'i',\n",
       " 11: 'j',\n",
       " 12: 'k',\n",
       " 13: 'l',\n",
       " 14: 'm',\n",
       " 15: 'n',\n",
       " 16: 'o',\n",
       " 17: 'p',\n",
       " 18: 'q',\n",
       " 19: 'r',\n",
       " 20: 's',\n",
       " 21: 't',\n",
       " 22: 'u',\n",
       " 23: 'v',\n",
       " 24: 'w',\n",
       " 25: 'x',\n",
       " 26: 'y',\n",
       " 27: 'z'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_to_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ade5b869-f94b-43e1-a9bb-ae9c310ae768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<': 0,\n",
       " '>': 1,\n",
       " 'a': 2,\n",
       " 'b': 3,\n",
       " 'c': 4,\n",
       " 'd': 5,\n",
       " 'e': 6,\n",
       " 'f': 7,\n",
       " 'g': 8,\n",
       " 'h': 9,\n",
       " 'i': 10,\n",
       " 'j': 11,\n",
       " 'k': 12,\n",
       " 'l': 13,\n",
       " 'm': 14,\n",
       " 'n': 15,\n",
       " 'o': 16,\n",
       " 'p': 17,\n",
       " 'q': 18,\n",
       " 'r': 19,\n",
       " 's': 20,\n",
       " 't': 21,\n",
       " 'u': 22,\n",
       " 'v': 23,\n",
       " 'w': 24,\n",
       " 'x': 25,\n",
       " 'y': 26,\n",
       " 'z': 27}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_to_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b0f149e-be67-4c5e-9793-fcb0359f66ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now the dataset creation! ###\n",
    "\n",
    "xs = [] # The ch1 (previous character)\n",
    "ys = [] # The ch2 (next character to be predicted - lables)\n",
    "\n",
    "for name in names[:1]: # looking at the first example name only\n",
    "    name = \"<\" + name + \">\"\n",
    "    for ch1, ch2 in zip(name, name[1:]):    \n",
    "        xs.append(ch_to_number[ch1])\n",
    "        ys.append(ch_to_number[ch2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "362ef9da-eed9-4e91-9f1f-1a67d0fc526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3e03dd2-a430-4af3-8d0f-e878dc46795d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<emma>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dae5e7c4-21fb-4afb-88fc-07bd3ef77039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  6, 14, 14,  2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8ae7147-2737-4e92-a975-1478951edb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 14, 14,  2,  1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ff3d3a-2fbc-488c-9939-ffc5eab8c40b",
   "metadata": {},
   "source": [
    "Here, we want the neural network to learn the weights that can assign the *highest* probability to the character `6` when the `0` comes the first, then assign `14` as the highest probability after the `6`.\n",
    "\n",
    "*(Note: Since I have taken `<` and `>` both as the special tokens in my example, the encoded values of `a`, `b`, `c` ... are increased by +1 than shown in the actual video.)*\n",
    "\n",
    "___\n",
    "> ‚ö† <br>The similar operation to `torch.tensor(...)` in numpy is `numpy.array(...)`\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6a017d-2623-49cc-80f7-e8dcf095603b",
   "metadata": {},
   "source": [
    "## üîß Building the Net\n",
    "So, the data is ready with us *(at least for single name \"emma\" now)*. We now need to think through what the *structure* of the net should be.\n",
    "\n",
    "Here we have the tensor like [0, 6, 14, 14, 2] which as a fixed length (here 5). So, should we straightly go forward with the net with input dimension 5? **No**. Because of the following reasons:\n",
    "1. We **don't have** the \"fixed\" size names in whole dataset\n",
    "2. We **are not** training the net to predict \"emma>\" when the \"<emma\" is given!\n",
    "\n",
    "See the things emerging? We are training the net to predict the next character, and not a whole word. And to predict a whole word, we would have different and more robust technique there.\n",
    "\n",
    "To tackle this problem, we will **again**, need to **convert** these numbers into some other encoding. Here we will use the `one-hot` encoding. Which is so popular in the standard \"ML\" problems in converting the string values into the numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a28a89c-bbd2-45e3-9417-ab04728d1014",
   "metadata": {},
   "source": [
    "### üìè Which has the same length!\n",
    "How many total characters do we have? Total `28` *(0 to 27)*. So, if we encode each character into one-hot, then we will have a dense matrix encoded for each character."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02abcf5-3c0a-457c-9721-6cdff697d00c",
   "metadata": {},
   "source": [
    "For our \"emma\" example, we have...\n",
    "\n",
    "    [\n",
    "        0  ‚Üí [1, 0, 0, 0, 0, 0, ...]\n",
    "        6  ‚Üí [0, 0, 0, 0, 0, 1, ...]\n",
    "        14 ‚Üí [0, 0, 0, 0, ... 1, 0, 0...]\n",
    "        14 ‚Üí [0, 0, 0, 0, ... 1, 0, 0...]\n",
    "        2  ‚Üí [0, 0, 1, 0, 0, 0, ...]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5fe669-1395-4a3c-b1c5-7e0feee6c306",
   "metadata": {},
   "source": [
    "This will be clearer soon. Here we just have converted the indexes into their respective encoded values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7439f74a-e876-4305-969f-e46eee3c4dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in pytorch\n",
    "encoded = torch.nn.functional.one_hot(xs)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ad87a0a-5e67-4c0f-b383-8742cf8518fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 15])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9788459-431d-4a9c-967f-d70ef91b50ba",
   "metadata": {},
   "source": [
    "See that, it simply has the length of `15` and **not** the `28`. The reason is it **automatically** calculated the size from the input (here the largest index is `14`).\n",
    "\n",
    "To solve this issue, we will use the `num_classes` attribute of the *one_hot* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea4085e0-a0e2-43c3-af28-4a34c06082d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with `num_classes` attribute\n",
    "encoded = torch.nn.functional.one_hot(xs, num_classes=28)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "530cbb2f-0222-4556-90d1-6e3a7e451df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 28])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a98e1663-693d-4323-8b05-41e275c723f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6f14ee-f5e0-46dc-aff3-30638fab6976",
   "metadata": {},
   "source": [
    "#### Cool! ü•Ç\n",
    "___\n",
    "\n",
    "> ‚ö† <br> Numpy ***doesn't directly support*** this type of one-hot conversion, but there are work arounds like using `np.identity()` and `np.zeros()` with leading operations. Checkout this [here](https://stackoverflow.com/questions/29831489/convert-array-of-indices-to-one-hot-encoded-array-in-numpy).\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da0fbe6a-e8a4-41c4-a636-a06a828dccfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c23f373520>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Just to see how that looks...\n",
    "plt.imshow(encoded)\n",
    "\n",
    "### üòì for some reason the kernel dies while plotting with plt, you may skip this cell it is harmless ###\n",
    "### if you face the same issue with plt/sns use: conda install freetype=2.10.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a93df3c-3738-4289-a43d-52a029364cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_encoded = encoded.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a41098-8ca6-47ac-9263-55b08e2aafef",
   "metadata": {},
   "source": [
    "We needed to perform the \"float conversion\" because it gives much more variability in the learning process in the NN than \"int\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d19bc55-e595-4af8-b74a-9287c1d80ec1",
   "metadata": {},
   "source": [
    "## üèãÔ∏è‚Äç‚ôÇÔ∏è Initializing the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a9d7f37-23cb-4145-b5ea-b060f40b20d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269],\n",
       "        [ 1.4873],\n",
       "        [ 0.9007],\n",
       "        [-2.1055],\n",
       "        [ 0.6784],\n",
       "        [-1.2345],\n",
       "        [-0.0431],\n",
       "        [-1.6047],\n",
       "        [-0.7521],\n",
       "        [ 1.6487],\n",
       "        [-0.3925],\n",
       "        [-1.4036],\n",
       "        [-1.1109],\n",
       "        [ 0.0915],\n",
       "        [-2.3169],\n",
       "        [-0.2168],\n",
       "        [-1.3847],\n",
       "        [-0.8712],\n",
       "        [-0.2234],\n",
       "        [ 1.7174],\n",
       "        [-0.5920],\n",
       "        [-0.0631],\n",
       "        [-0.8286],\n",
       "        [ 0.3309],\n",
       "        [-1.5576],\n",
       "        [ 0.9956],\n",
       "        [-0.8798],\n",
       "        [-0.6011]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "W = torch.randn((28, 1), generator=generator) # sampling from the standard normal distribution\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef86c15-90ef-4bef-8a2f-dafba00f16e6",
   "metadata": {},
   "source": [
    "___\n",
    "> ‚ö† <br> Numpy equivalent is `numpy.random.randn(28, 1)`.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fef88a-f922-41e0-bc21-803e356337ff",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ The very first operation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85118da4-4d42-43f1-a08a-c6e725d8185f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269],\n",
       "        [-0.0431],\n",
       "        [-2.3169],\n",
       "        [-2.3169],\n",
       "        [ 0.9007]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs_encoded @ W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb58a3f6-763c-4d7e-860c-352dbc344bdf",
   "metadata": {},
   "source": [
    "This was our **forward pass** mate!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda6bf44-dd57-489a-90a4-def507ab9c52",
   "metadata": {},
   "source": [
    "## üòµ Feeling some sense of D√©j√† vu?\n",
    "Let's recap a bit. Let's refer to the micrograd for this.\n",
    "\n",
    "Recall that:\n",
    "\n",
    "| **In Micrograd** | **In Torch** | **Comparision**                                                                                                                                                        |\n",
    "|------------------|--------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| `Layer`          | `tensor()`   | The **Layer** stored the `Neurons`. Here we have the tensor() which is the collections of tensor objects.                                                              |\n",
    "| `Neuron`         | --           | The **Neuron** was used to perform automatic multiplication *(the matrix multiplication)* with the data. In torch, we do that manually *(for now)* by `xs_encoded @ W` |\n",
    "| `Value`          | `tensor`     | Which was the atomic object which stores the `data` and `grad` values. They can be multiplied, stored, accessed, updated, connected etc.                            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb86904-6be6-4e68-b268-7e461a11fb47",
   "metadata": {},
   "source": [
    "So if we had the Micrograd what we would have done is..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdf3ed2-f3e0-4cae-b790-054da0b1ec77",
   "metadata": {},
   "source": [
    "```python\n",
    "# Define the neuron which takes 28 input shape\n",
    "neuron = Neuron(nin=28)\n",
    "\n",
    "# Does the matrix multiplication\n",
    "result = neuron(xs_encoded[0])\n",
    "\n",
    "# result\n",
    "1.9269\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d5ac11-e298-4475-a70d-327fad20d71c",
   "metadata": {},
   "source": [
    "And so, we will pass all characters (xs_encoded[1,2,3,4...]) through the neuron, and get the result, and then apply the activation and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63825950-9c4c-4c56-aff7-d4fbf28d7947",
   "metadata": {},
   "source": [
    "Till now, we have just:\n",
    "- Made `28` Value nodes inside\n",
    "- Multiplied and added them with the weights `W`\n",
    "- Thus there is a large structure created for that single neuron\n",
    "- That's it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24975a5-6a4e-4a97-8152-648e614a2489",
   "metadata": {},
   "source": [
    "## Coming out of the D√©j√† vu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e54984-ba86-4352-89d0-dd0542718dc2",
   "metadata": {},
   "source": [
    "# ü§∑‚Äç‚ôÄÔ∏è So what we did here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce483cf-35bf-46ae-a683-b74286501e1b",
   "metadata": {},
   "source": [
    "Till now..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1afd10-2097-496d-b5cf-84332e967c04",
   "metadata": {},
   "source": [
    "<img src=\"./Images/Before.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b7f69-adc8-4add-a685-a863bbf675fc",
   "metadata": {},
   "source": [
    "And now..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bb5dd4-1b72-404f-b551-6e27ed7307b9",
   "metadata": {},
   "source": [
    "<img src=\"./Images/After.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba325833-47d4-41df-a378-e83366fee9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269e+00,  1.4873e+00,  9.0072e-01, -2.1055e+00,  6.7842e-01,\n",
       "         -1.2345e+00, -4.3067e-02, -1.6047e+00, -7.5214e-01,  1.6487e+00,\n",
       "         -3.9248e-01, -1.4036e+00, -7.2788e-01, -5.5943e-01, -7.6884e-01,\n",
       "          7.6245e-01,  1.6423e+00, -1.5960e-01, -4.9740e-01,  4.3959e-01,\n",
       "         -7.5813e-01,  1.0783e+00,  8.0080e-01,  1.6806e+00,  1.2791e+00,\n",
       "          1.2964e+00,  6.1047e-01,  1.3347e+00],\n",
       "        [-2.3162e-01,  4.1759e-02, -2.5158e-01,  8.5986e-01, -1.3847e+00,\n",
       "         -8.7124e-01, -2.2337e-01,  1.7174e+00,  3.1888e-01, -4.2452e-01,\n",
       "          3.0572e-01, -7.7459e-01, -1.5576e+00,  9.9564e-01, -8.7979e-01,\n",
       "         -6.0114e-01, -1.2742e+00,  2.1228e+00, -1.2347e+00, -4.8791e-01,\n",
       "         -9.1382e-01, -6.5814e-01,  7.8024e-02,  5.2581e-01, -4.8799e-01,\n",
       "          1.1914e+00, -8.1401e-01, -7.3599e-01],\n",
       "        [-1.4032e+00,  3.6004e-02, -6.3477e-02,  6.7561e-01, -9.7807e-02,\n",
       "          1.8446e+00, -1.1845e+00,  1.3835e+00,  1.4451e+00,  8.5641e-01,\n",
       "          2.2181e+00,  5.2317e-01,  3.4665e-01, -1.9733e-01, -1.0546e+00,\n",
       "          1.2780e+00, -1.7219e-01,  5.2379e-01,  5.6622e-02,  4.2630e-01,\n",
       "          5.7501e-01, -6.4172e-01, -2.2064e+00, -7.5080e-01,  1.0868e-02,\n",
       "         -3.3874e-01, -1.3407e+00, -5.8537e-01],\n",
       "        [ 5.3619e-01,  5.2462e-01,  1.1412e+00,  5.1644e-02,  7.4395e-01,\n",
       "         -4.8158e-01, -1.0495e+00,  6.0390e-01, -1.7223e+00, -8.2777e-01,\n",
       "          1.3347e+00,  4.8354e-01, -2.5095e+00,  4.8800e-01,  7.8459e-01,\n",
       "          2.8647e-02,  6.4076e-01,  5.8325e-01,  1.0669e+00, -4.5015e-01,\n",
       "         -1.8527e-01,  7.5276e-01,  4.0476e-01,  1.7847e-01,  2.6491e-01,\n",
       "          1.2732e+00, -1.3109e-03, -3.0360e-01],\n",
       "        [-1.4570e+00, -1.0234e-01, -5.9915e-01,  4.7706e-01,  7.2618e-01,\n",
       "          9.1152e-02, -3.8907e-01,  5.2792e-01, -1.2685e-02,  2.4084e-01,\n",
       "          1.3254e-01,  7.6424e-01,  1.0950e+00,  3.3989e-01,  7.1997e-01,\n",
       "          4.1141e-01,  1.9312e+00,  1.0119e+00, -1.4364e+00, -1.1299e+00,\n",
       "         -1.3603e-01,  1.6354e+00,  6.5474e-01,  5.7600e-01,  1.1415e+00,\n",
       "          1.8565e-02, -1.8058e+00,  9.2543e-01],\n",
       "        [-3.7534e-01,  1.0331e+00, -6.8665e-01,  6.3681e-01, -9.7267e-01,\n",
       "          9.5846e-01,  1.6192e+00,  1.4506e+00,  2.6948e-01, -2.1038e-01,\n",
       "         -7.3280e-01,  1.0430e-01,  3.4875e-01,  9.6759e-01, -4.6569e-01,\n",
       "          1.6048e+00, -2.4801e+00, -4.1754e-01, -1.1955e+00,  8.1234e-01,\n",
       "         -1.9006e+00,  2.2858e-01,  2.4859e-02, -3.4595e-01,  2.8683e-01,\n",
       "         -7.3084e-01,  1.7482e-01, -1.0939e+00],\n",
       "        [-1.6022e+00,  1.3529e+00,  1.2888e+00,  5.2295e-02, -1.5469e+00,\n",
       "          7.5671e-01,  7.7552e-01,  2.0265e+00,  3.5818e-02,  1.2059e-01,\n",
       "         -8.0566e-01, -2.0758e-01, -9.3195e-01, -1.5910e+00, -1.1360e+00,\n",
       "         -5.2260e-01, -5.1877e-01, -1.5013e+00, -1.9267e+00,  1.2785e-01,\n",
       "          1.0229e+00, -5.5580e-01,  7.0427e-01,  7.0988e-01,  1.7744e+00,\n",
       "         -9.2155e-01,  9.6245e-01, -3.3702e-01],\n",
       "        [-1.1753e+00,  3.5806e-01,  4.7877e-01,  1.3537e+00,  5.2606e-01,\n",
       "          2.1120e+00, -5.2076e-01, -9.3201e-01,  1.8516e-01,  1.0687e+00,\n",
       "          1.3065e+00,  4.5983e-01, -8.1463e-01, -1.0212e+00, -4.9492e-01,\n",
       "         -5.9225e-01,  1.5432e-01,  4.4077e-01, -1.4829e-01, -2.3184e+00,\n",
       "         -3.9800e-01,  1.0805e+00, -1.7809e+00,  1.5080e+00,  3.0943e-01,\n",
       "         -5.0031e-01,  1.0350e+00,  1.6896e+00],\n",
       "        [-4.5051e-03,  1.6668e+00,  1.5392e-01, -1.0603e+00, -5.7266e-01,\n",
       "          8.3568e-02,  3.9991e-01,  1.9892e+00, -7.1988e-02, -9.0609e-01,\n",
       "         -2.0487e+00, -1.0811e+00,  1.7623e-02,  7.8226e-02,  1.9316e-01,\n",
       "          4.0967e-01, -9.2913e-01,  2.7619e-01, -5.3888e-01,  4.6258e-01,\n",
       "         -8.7189e-01, -2.7118e-02, -3.5325e-01,  1.4639e+00,  1.2554e+00,\n",
       "         -7.1496e-01,  8.5392e-01,  5.1299e-01],\n",
       "        [ 5.3973e-01,  5.6551e-01,  5.0579e-01,  2.2245e-01, -6.8548e-01,\n",
       "          5.6356e-01, -1.5072e+00, -1.6107e+00, -1.4790e+00,  4.3227e-01,\n",
       "         -1.2503e-01,  7.8212e-01, -1.5988e+00, -1.0913e-01,  7.1520e-01,\n",
       "          3.9139e-02,  1.3059e+00,  2.4659e-01, -1.9776e+00,  1.7896e-02,\n",
       "         -1.3793e+00,  6.2580e-01, -2.5850e+00, -2.4000e-02, -1.2219e-01,\n",
       "         -7.4700e-01,  1.7093e+00,  5.7923e-02],\n",
       "        [ 1.1930e+00,  1.9373e+00,  7.2871e-01,  9.8089e-01,  4.1459e-01,\n",
       "          1.1566e+00,  2.6905e-01, -3.6629e-02,  9.7329e-01, -1.0151e+00,\n",
       "         -5.4192e-01, -4.4102e-01, -3.1362e-01, -1.2925e-01, -7.1496e-01,\n",
       "         -4.7562e-02,  2.0207e+00,  2.5392e-01,  9.3644e-01,  7.1224e-01,\n",
       "         -3.1766e-02,  1.0164e-01,  1.3433e+00,  7.1327e-01,  4.0380e-01,\n",
       "         -7.1398e-01,  8.3373e-01, -9.5855e-01],\n",
       "        [ 4.5363e-01,  1.2461e+00, -2.3065e+00, -1.2869e+00,  1.7989e-01,\n",
       "         -2.1268e+00, -1.3408e-01, -1.0408e+00, -7.6472e-01, -5.5283e-02,\n",
       "          1.2049e+00, -9.8247e-01,  4.3344e-01, -7.1719e-01,  1.0554e+00,\n",
       "         -1.4534e+00,  4.6515e-01,  3.7139e-01, -4.6568e-03,  7.9549e-02,\n",
       "          3.7818e-01,  7.0511e-01, -1.7237e+00, -8.4348e-01,  4.3514e-01,\n",
       "          2.6589e-01, -5.8710e-01,  8.2689e-02],\n",
       "        [ 8.8538e-01,  1.8244e-01,  7.8638e-01, -5.7920e-02,  5.6667e-01,\n",
       "         -7.0976e-01, -4.8751e-01,  5.0096e-02,  6.0841e-01,  1.6309e+00,\n",
       "         -8.4723e-02,  1.0844e+00,  9.4777e-01, -6.7663e-01, -5.7302e-01,\n",
       "         -3.3032e-01, -7.9394e-01,  3.7523e-01,  8.7910e-02, -1.2415e+00,\n",
       "         -3.2025e-01, -8.4438e-01, -5.5135e-01,  1.9890e+00,  1.9003e+00,\n",
       "          1.6951e+00,  2.8090e-02, -1.7537e-01],\n",
       "        [-1.7735e+00, -7.0464e-01, -3.9465e-01,  1.8868e+00, -2.1844e-01,\n",
       "          1.6630e-01,  2.1442e+00,  1.7046e+00,  3.4590e-01,  6.4248e-01,\n",
       "         -2.0395e-01,  6.8537e-01, -1.3969e-01, -1.1808e+00, -1.2829e+00,\n",
       "          4.4849e-01, -5.9074e-01,  8.5406e-01, -4.9007e-01, -3.5946e-01,\n",
       "          6.6637e-01, -7.4265e-02, -2.0960e-01,  1.6632e-01,  1.4703e+00,\n",
       "         -9.3909e-01, -6.0132e-01, -9.9640e-02],\n",
       "        [-9.8515e-01, -2.4885e+00, -3.3132e-01,  8.4358e-01,  9.8745e-01,\n",
       "         -3.3197e-01, -8.0762e-01,  8.2436e-01,  2.4700e-02, -1.0641e+00,\n",
       "         -7.6019e-01, -4.0751e-01,  9.6236e-01, -1.4264e-01,  1.5271e-01,\n",
       "         -3.8802e-02,  9.4461e-01, -1.5824e+00,  9.8713e-01,  1.1457e+00,\n",
       "         -1.4181e-01, -2.7634e-01, -1.9321e-01,  7.7678e-01,  6.8388e-01,\n",
       "         -1.3246e+00, -5.1608e-01,  6.0018e-01],\n",
       "        [-4.7022e-01, -6.0864e-01, -4.6192e-02, -1.6457e+00, -4.8333e-01,\n",
       "         -7.4029e-01,  3.1428e-01,  1.4156e-01,  1.0348e+00, -6.2644e-01,\n",
       "         -5.1509e-01,  6.9029e-01, -4.9400e-01,  1.1366e+00, -4.6184e-01,\n",
       "          1.4200e+00,  8.4852e-01, -4.7891e-02,  6.6856e-01,  1.0430e+00,\n",
       "          6.8990e-01, -1.3129e+00,  3.7804e-02, -1.1702e+00, -1.0319e-01,\n",
       "          1.1895e+00,  7.6069e-01, -7.4630e-01],\n",
       "        [-1.3839e+00,  4.8687e-01, -1.0020e+00,  3.2949e-02, -4.2920e-01,\n",
       "         -9.8180e-01, -6.4206e-01,  8.2659e-01,  1.5914e+00, -1.2081e-01,\n",
       "         -4.8302e-01,  1.1330e-01,  7.7151e-02, -9.2281e-01, -1.2620e+00,\n",
       "          1.0861e+00,  1.0966e+00, -6.8369e-01,  6.6043e-02, -7.7380e-04,\n",
       "          1.6206e-01,  1.1960e+00, -1.3062e+00, -1.4040e+00, -1.0597e+00,\n",
       "          3.0573e-01,  4.1506e-01, -7.1741e-01],\n",
       "        [ 2.8340e+00,  1.9535e+00,  2.0487e+00, -1.0880e+00,  1.6217e+00,\n",
       "          8.5127e-01, -4.0047e-01, -6.0883e-01, -5.0810e-01, -6.1849e-01,\n",
       "         -1.6470e+00, -1.0362e+00, -4.5031e-01, -7.2966e-02, -5.4795e-01,\n",
       "         -1.1426e+00, -4.4875e-01, -3.0454e-02,  3.8303e-01, -4.4770e-02,\n",
       "          1.1799e+00, -3.3143e-01,  6.4950e-01,  9.4959e-02, -7.5259e-01,\n",
       "         -6.4723e-01, -1.2823e+00,  1.9653e+00],\n",
       "        [-9.6385e-01, -2.5668e+00,  7.0961e-01,  8.1984e-01,  6.2145e-01,\n",
       "          4.2319e-01, -3.3890e-01,  5.1797e-01, -1.3638e+00,  1.9296e-01,\n",
       "         -6.1033e-01,  1.6323e-01,  1.5102e+00,  2.1230e-01, -7.2520e-01,\n",
       "         -9.5277e-01,  5.2169e-01, -4.6387e-01,  1.8238e-01, -3.8666e-01,\n",
       "         -1.7907e+00,  9.3293e-02, -1.9153e+00, -6.4218e-01,  1.3439e+00,\n",
       "         -1.2922e+00,  7.6624e-01,  6.4540e-01],\n",
       "        [ 3.5332e-01, -2.6475e+00, -1.4575e+00, -9.7124e-01,  2.5403e-01,\n",
       "         -1.7906e-01,  1.1993e+00, -4.2922e-01,  1.0103e+00,  6.1104e-01,\n",
       "          1.2208e+00, -6.0764e-01, -1.7376e+00, -1.2535e-01, -1.3658e+00,\n",
       "          1.1117e+00, -6.2280e-01, -7.8918e-01, -1.6782e-01,  1.6433e+00,\n",
       "          2.0071e+00, -1.2531e+00,  1.1189e+00,  1.7733e+00, -2.0717e+00,\n",
       "         -4.1253e-01, -9.7696e-01, -3.3634e-02],\n",
       "        [ 1.8595e+00,  2.6221e+00,  3.6905e-01,  3.8030e-01,  1.9898e-01,\n",
       "         -2.3609e-01,  3.0341e-01, -4.5008e-01,  4.7390e-01,  6.5034e-01,\n",
       "          1.1662e+00,  1.6936e-02,  5.3259e-01, -6.0354e-01, -1.7426e-01,\n",
       "          6.0921e-01, -8.0322e-01, -1.1209e+00,  1.9564e-01, -7.8152e-01,\n",
       "         -1.7899e+00, -2.6157e-01, -4.4025e-01,  2.1848e+00, -4.8010e-01,\n",
       "         -1.2872e+00,  7.3888e-01,  3.3895e-02],\n",
       "        [-3.1229e-01, -2.5418e-01, -1.2055e+00, -9.5421e-01,  6.1277e-02,\n",
       "          8.5261e-02,  7.4813e-01, -1.6356e-01, -9.0856e-01,  3.1300e-01,\n",
       "          8.0505e-01, -1.1134e+00,  4.9816e-01, -1.2000e+00,  1.2711e-01,\n",
       "          4.4037e-01,  6.3777e-01,  1.5979e-01,  1.7698e+00,  6.2682e-01,\n",
       "         -1.8737e+00,  2.3259e+00, -9.2039e-01,  6.6611e-01, -4.4026e-01,\n",
       "         -2.3180e+00,  1.2946e+00,  2.2267e-01],\n",
       "        [-8.4834e-01,  1.6489e+00,  1.6006e+00, -7.8589e-02,  4.3105e-01,\n",
       "          3.6835e-01,  7.6380e-01,  1.1792e+00, -4.1379e-01,  5.1841e-01,\n",
       "         -7.0154e-01, -4.3234e-01,  1.4148e-01,  7.1104e-02,  5.6335e-01,\n",
       "         -5.7864e-01, -1.0838e+00, -3.8893e-01,  8.1261e-01,  1.4981e+00,\n",
       "          4.3896e-02,  1.4443e+00,  2.3203e-01,  5.0650e-01, -1.2787e+00,\n",
       "         -3.8427e-02,  1.9138e+00,  3.3784e-01],\n",
       "        [ 1.2506e-01, -7.6215e-01, -1.1906e+00,  7.7561e-01,  4.5572e-01,\n",
       "          2.5033e-01, -1.3611e+00,  1.8018e+00, -7.4342e-02, -1.5664e-01,\n",
       "         -8.7085e-01, -6.4110e-01, -4.1456e-01, -6.9024e-01, -2.2996e-01,\n",
       "         -2.1723e+00,  8.7683e-02,  1.0938e+00, -1.1772e-01, -2.9864e-01,\n",
       "         -9.5362e-01, -9.2473e-02, -1.0167e+00, -7.6757e-03, -5.1822e-01,\n",
       "          8.3954e-01,  5.8523e-02, -1.6682e+00],\n",
       "        [ 2.1296e+00, -1.5181e+00,  1.3873e-01, -1.1798e+00, -5.2974e-01,\n",
       "          9.6252e-01,  2.7944e-01, -5.7182e-01, -2.7936e+00, -7.1115e-01,\n",
       "          5.2352e-01, -1.7106e+00,  8.3849e-01, -2.6985e-01,  1.2306e-01,\n",
       "          8.7575e-01,  1.5133e-01,  7.3939e-01,  2.7310e-01,  2.7312e+00,\n",
       "          4.3201e-01, -3.0918e-01, -9.6581e-02,  1.5419e+00, -1.0874e-01,\n",
       "         -4.1890e-01,  1.4384e+00, -7.0684e-01],\n",
       "        [-1.2520e+00,  3.0250e+00,  1.3463e+00,  8.5561e-01,  3.2203e-01,\n",
       "          4.4606e-01,  1.5230e+00,  1.2805e+00, -1.1616e-01,  1.3705e+00,\n",
       "         -4.8094e-01, -9.9036e-01, -1.3642e+00,  8.2057e-03, -4.0586e-01,\n",
       "         -7.1109e-01, -3.4958e-01,  3.7975e-01,  9.9930e-01,  1.2752e+00,\n",
       "          9.5949e-01,  1.0351e-01,  8.2903e-01,  2.0921e+00,  7.9531e-01,\n",
       "          2.7928e-01,  1.8645e-01,  3.5471e-01],\n",
       "        [ 9.0639e-02,  1.7423e+00, -1.2660e+00,  3.8916e-01,  3.4288e-01,\n",
       "         -1.4591e+00, -1.4937e+00, -2.2139e-01,  2.2524e-01, -7.7245e-02,\n",
       "          9.8569e-01,  1.2783e+00,  2.8815e-01,  8.6905e-01, -8.0971e-01,\n",
       "         -1.4299e+00,  4.5902e-01,  5.3093e-01, -1.3615e+00,  1.9562e+00,\n",
       "          1.7685e+00, -9.8580e-01, -1.2371e+00, -2.3019e+00, -1.0087e-03,\n",
       "         -8.4943e-01, -1.6594e+00,  3.0629e-01],\n",
       "        [ 1.1820e+00,  3.2603e-01, -3.8945e-01,  2.8544e+00,  8.2437e-01,\n",
       "          7.9835e-01,  1.8890e+00,  5.9346e-01,  6.9654e-02, -1.6034e+00,\n",
       "         -4.2982e-01,  5.7616e-01,  3.4436e-01, -3.1016e+00, -1.4587e+00,\n",
       "         -1.4318e+00, -6.0713e-01, -2.5974e-01, -7.1902e-01, -3.8583e-01,\n",
       "          5.2335e-01, -8.2118e-01, -4.7087e-01,  6.0164e-01, -2.8251e-01,\n",
       "          7.6927e-01, -7.6689e-01, -9.4949e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "W = torch.randn((28, 28), generator=generator, requires_grad=True) # ignore this `required_grad` for now\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafb3447-400f-4ca1-ab50-3f757daaa040",
   "metadata": {},
   "source": [
    "Fine?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1f35d8-e0c6-4835-a081-901e710070b3",
   "metadata": {},
   "source": [
    "### The forward pass!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "179cadc6-b856-48f0-a127-67655c4bca23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431, -1.6047,\n",
       "         -0.7521,  1.6487, -0.3925, -1.4036, -0.7279, -0.5594, -0.7688,  0.7624,\n",
       "          1.6423, -0.1596, -0.4974,  0.4396, -0.7581,  1.0783,  0.8008,  1.6806,\n",
       "          1.2791,  1.2964,  0.6105,  1.3347],\n",
       "        [-1.6022,  1.3529,  1.2888,  0.0523, -1.5469,  0.7567,  0.7755,  2.0265,\n",
       "          0.0358,  0.1206, -0.8057, -0.2076, -0.9319, -1.5910, -1.1360, -0.5226,\n",
       "         -0.5188, -1.5013, -1.9267,  0.1279,  1.0229, -0.5558,  0.7043,  0.7099,\n",
       "          1.7744, -0.9216,  0.9624, -0.3370],\n",
       "        [-0.9852, -2.4885, -0.3313,  0.8436,  0.9874, -0.3320, -0.8076,  0.8244,\n",
       "          0.0247, -1.0641, -0.7602, -0.4075,  0.9624, -0.1426,  0.1527, -0.0388,\n",
       "          0.9446, -1.5824,  0.9871,  1.1457, -0.1418, -0.2763, -0.1932,  0.7768,\n",
       "          0.6839, -1.3246, -0.5161,  0.6002],\n",
       "        [-0.9852, -2.4885, -0.3313,  0.8436,  0.9874, -0.3320, -0.8076,  0.8244,\n",
       "          0.0247, -1.0641, -0.7602, -0.4075,  0.9624, -0.1426,  0.1527, -0.0388,\n",
       "          0.9446, -1.5824,  0.9871,  1.1457, -0.1418, -0.2763, -0.1932,  0.7768,\n",
       "          0.6839, -1.3246, -0.5161,  0.6002],\n",
       "        [-1.4032,  0.0360, -0.0635,  0.6756, -0.0978,  1.8446, -1.1845,  1.3835,\n",
       "          1.4451,  0.8564,  2.2181,  0.5232,  0.3466, -0.1973, -1.0546,  1.2780,\n",
       "         -0.1722,  0.5238,  0.0566,  0.4263,  0.5750, -0.6417, -2.2064, -0.7508,\n",
       "          0.0109, -0.3387, -1.3407, -0.5854]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff = xs_encoded @ W\n",
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26f28d5a-7fd2-4f1f-a031-432b671e6ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 28])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dd14ec-66e8-4c98-89a0-b98d4addadce",
   "metadata": {},
   "source": [
    "Which is the output... for each latter for \"<emma\" coming out of each `28` neurons!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb24379a-fd5e-423f-bbbb-69aa19100299",
   "metadata": {},
   "source": [
    "# \"The bumbest neural network\" ft. Karpathy\n",
    "As said, this is the beginning of the NN, we will just create the first layer, and will stop! So, there are no hidden layers, no output layers! **Just the SINGLE layer which serves 3 purposes at once**!\n",
    "\n",
    "‚öô That does:\n",
    "1. Take the input characters one-by-one (one hot encoded format)\n",
    "2. Perform the matrix multiplication\n",
    "3. That's it *(for now - later we will do the logit and softmax etc - but the overall steps are just freaking 3.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc101c0-94e0-4144-b518-62566fb796e9",
   "metadata": {},
   "source": [
    "# Okay, there are the outputs but...\n",
    "üôÑ What do we want them to **be**?\n",
    "\n",
    "This is the question with weight, please consider it. Don't ignore it. Now, we have the vanilla neural net, which is untrained and it has random weights *(ranging from -3 to 3 generally)* and we have the first ever forward pass.\n",
    "\n",
    "So, that's the output! But they are indeed **not the counts** that we expect, right? We started the discussion with \"replicating\" the bigram table in mind, but through learning... here we just see a bunch of floats... where are the counts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bada2355-e8b3-44d0-b974-8af8962dd9e0",
   "metadata": {},
   "source": [
    "### To make it clearer...\n",
    "\n",
    "üëâ In the manual way, from the bigram table:\n",
    "- If I want to predict the **next** token for character `e` then I would take that from the table.\n",
    "- Lookup for the `e` row, and get the counts.\n",
    "\n",
    "        Suppose we got: (please reset the browser zoom to view the following in 2 lines. :)\n",
    "         ea, eb, ec, ed,  ef, eg, eh, ei, ej, ek, el, em, en, eo, ep, eq, er,  es, et, eu, ev, ew,  ex, ey, ez, e>\n",
    "        [111, 3, 55, 44, 666, 77, 22,  8, 99,  0,  0,  0,  0,  0,  3,  3, 121, 22, 33, 45, 66, 77, 867, 56,  0, 45]\n",
    "\n",
    "- Thus the above is the frequency, we then **convert** those into the probability and then sample from it.\n",
    "\n",
    "üëâ In the NN way we have:\n",
    "- Passed the character `e` to the network and the network has given\n",
    "\n",
    "        The following for the `e`\n",
    "        [-1.6022,  1.3529,  1.2888,  0.0523, -1.5469,  0.7567,  0.7755,  2.0265,\n",
    "          0.0358,  0.1206, -0.8057, -0.2076, -0.9319, -1.5910, -1.1360, -0.5226,\n",
    "         -0.5188, -1.5013, -1.9267,  0.1279,  1.0229, -0.5558,  0.7043,  0.7099,\n",
    "          1.7744, -0.9216,  0.9624, -0.3370]\n",
    "          \n",
    "\n",
    "> The point for the discussion above it to see the process, where we are. We have finally made to it that the NN is able to provide some numbers that represent the next token... but still it is the random model and will produce the ***garbage text***."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284767a0-8694-458c-8935-f3b01d383a52",
   "metadata": {},
   "source": [
    "## So, the Log Counts.\n",
    "So, there we have the negative numbers and positive numbers all around the place in the `28` tensor. While, our bigram was returning the \"positive\" count values (and then the probabitlity.)\n",
    "\n",
    "To deal with this, we somehow need to \"convert\" these into the positive number **and of course** we should not expect the neural net to output the \"counts\" as in the bigram because it is not what they are ment for! So, we will simply do some **transformation** so that the numbers are more interpretable.\n",
    "\n",
    "___\n",
    "\n",
    "If you can **recall** the log's behavior, you would observe that: \n",
    "> *\"Any value which is between 0 and 1 will have log in negative. <br>While value more than 1 will have log in positive.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7569a7d0-995b-4b95-ab31-142cd3eb1b87",
   "metadata": {},
   "source": [
    "So the \"output\" that the NN has given *can* represent out **counts** (loosely speaking) and we can consider them as the logs! Because next up we will use the `exp` to make them positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ba9298-08ad-4465-9bf2-27efc80eb136",
   "metadata": {},
   "source": [
    "## Enough chatter. Let's take action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9559fc1-9657-4ff3-8048-9f76b3d54634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431, -1.6047,\n",
       "         -0.7521,  1.6487, -0.3925, -1.4036, -0.7279, -0.5594, -0.7688,  0.7624,\n",
       "          1.6423, -0.1596, -0.4974,  0.4396, -0.7581,  1.0783,  0.8008,  1.6806,\n",
       "          1.2791,  1.2964,  0.6105,  1.3347],\n",
       "        [-1.6022,  1.3529,  1.2888,  0.0523, -1.5469,  0.7567,  0.7755,  2.0265,\n",
       "          0.0358,  0.1206, -0.8057, -0.2076, -0.9319, -1.5910, -1.1360, -0.5226,\n",
       "         -0.5188, -1.5013, -1.9267,  0.1279,  1.0229, -0.5558,  0.7043,  0.7099,\n",
       "          1.7744, -0.9216,  0.9624, -0.3370],\n",
       "        [-0.9852, -2.4885, -0.3313,  0.8436,  0.9874, -0.3320, -0.8076,  0.8244,\n",
       "          0.0247, -1.0641, -0.7602, -0.4075,  0.9624, -0.1426,  0.1527, -0.0388,\n",
       "          0.9446, -1.5824,  0.9871,  1.1457, -0.1418, -0.2763, -0.1932,  0.7768,\n",
       "          0.6839, -1.3246, -0.5161,  0.6002],\n",
       "        [-0.9852, -2.4885, -0.3313,  0.8436,  0.9874, -0.3320, -0.8076,  0.8244,\n",
       "          0.0247, -1.0641, -0.7602, -0.4075,  0.9624, -0.1426,  0.1527, -0.0388,\n",
       "          0.9446, -1.5824,  0.9871,  1.1457, -0.1418, -0.2763, -0.1932,  0.7768,\n",
       "          0.6839, -1.3246, -0.5161,  0.6002],\n",
       "        [-1.4032,  0.0360, -0.0635,  0.6756, -0.0978,  1.8446, -1.1845,  1.3835,\n",
       "          1.4451,  0.8564,  2.2181,  0.5232,  0.3466, -0.1973, -1.0546,  1.2780,\n",
       "         -0.1722,  0.5238,  0.0566,  0.4263,  0.5750, -0.6417, -2.2064, -0.7508,\n",
       "          0.0109, -0.3387, -1.3407, -0.5854]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consider these as the log counts\n",
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22660d49-7ff7-4333-a986-dadbbdf92cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.8683, 4.4251, 2.4614, 0.1218, 1.9708, 0.2910, 0.9578, 0.2010, 0.4714,\n",
       "         5.2003, 0.6754, 0.2457, 0.4829, 0.5715, 0.4636, 2.1435, 5.1671, 0.8525,\n",
       "         0.6081, 1.5521, 0.4685, 2.9397, 2.2273, 5.3689, 3.5935, 3.6562, 1.8413,\n",
       "         3.7990],\n",
       "        [0.2015, 3.8686, 3.6285, 1.0537, 0.2129, 2.1312, 2.1717, 7.5878, 1.0365,\n",
       "         1.1282, 0.4468, 0.8126, 0.3938, 0.2037, 0.3211, 0.5930, 0.5953, 0.2228,\n",
       "         0.1456, 1.1364, 2.7813, 0.5736, 2.0224, 2.0337, 5.8967, 0.3979, 2.6181,\n",
       "         0.7139],\n",
       "        [0.3734, 0.0830, 0.7180, 2.3247, 2.6844, 0.7175, 0.4459, 2.2804, 1.0250,\n",
       "         0.3450, 0.4676, 0.6653, 2.6179, 0.8671, 1.1650, 0.9619, 2.5718, 0.2055,\n",
       "         2.6835, 3.1446, 0.8678, 0.7586, 0.8243, 2.1745, 1.9815, 0.2659, 0.5969,\n",
       "         1.8225],\n",
       "        [0.3734, 0.0830, 0.7180, 2.3247, 2.6844, 0.7175, 0.4459, 2.2804, 1.0250,\n",
       "         0.3450, 0.4676, 0.6653, 2.6179, 0.8671, 1.1650, 0.9619, 2.5718, 0.2055,\n",
       "         2.6835, 3.1446, 0.8678, 0.7586, 0.8243, 2.1745, 1.9815, 0.2659, 0.5969,\n",
       "         1.8225],\n",
       "        [0.2458, 1.0367, 0.9385, 1.9652, 0.9068, 6.3255, 0.3059, 3.9890, 4.2424,\n",
       "         2.3547, 9.1896, 1.6874, 1.4143, 0.8209, 0.3483, 3.5894, 0.8418, 1.6884,\n",
       "         1.0583, 1.5316, 1.7771, 0.5264, 0.1101, 0.4720, 1.0109, 0.7127, 0.2617,\n",
       "         0.5569]], grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expontiating them...\n",
    "ff.exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad22313-c570-473f-800b-8be8f932b844",
   "metadata": {},
   "source": [
    "- See! All values which were negative are now **below** `1`\n",
    "- All value which were positive are now **more than** `1`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd7aec0-491b-47e4-8d0a-bf1497e75eb6",
   "metadata": {},
   "source": [
    "### What we have done simply is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3258f37d-2fea-4d2a-9c11-42d3bcba7b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let take some number\n",
    "x = 0.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1966ce6c-b9f2-43dc-8549-47d9af691e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0788096613719298"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Its log will be\n",
    "np.log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ab42647-991e-40bd-88f1-1b9800f31764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3400000000000001"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And to get that original number back...\n",
    "np.exp(-1.0788096613719298)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ef540d-31c7-409c-ad27-40050f3a9b24",
   "metadata": {},
   "source": [
    "### $x ‚Üí log ‚Üí exp ‚Üí x$\n",
    "\n",
    "That's why **we considered** the outputs of NN to be the \"logs\" so that if we use the `exp` on them, we can get **the original values back**. Which are not the original so to say, but ***interpretable enough*** for us to go with üòä\n",
    "\n",
    "> **Wait a minute üëÄ**<br><img src=\"https://media.tenor.com/IJwsfw7ToiQAAAAd/wait-what.gif\" width=\"200\" height=\"200\" alt=\"Wait What GIF - Wait What Meme GIFs\" style=\"max-width: 683px;\"> <br> Can't we just use the `abs()` to make things positive!? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241a7644-a29b-4618-977a-83fda3e6c478",
   "metadata": {},
   "source": [
    "### Well, we can't!\n",
    "You can't possibly make the negatives, positive just because they are negatives! <br>\n",
    "- They are negative for some reason.\n",
    "- Let's say if there is a number `-1.23` and ***also*** there is another number `1.23` in the same array, then if we use `abs()`, both **will be interpreted the same**!\n",
    "- So, use some \"intelligent\" transformer, like `exp()` üòä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634d5ce1-b4ba-4b42-ad18-37e286da2f63",
   "metadata": {},
   "source": [
    "## Sorry, went too far in the discussion\n",
    "But that was required. Let's continue down to the makemore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76df3c65-f848-45d6-ba79-069e280a4549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we have some \"so called\" - \"counts\" we now need the probability.\n",
    "\n",
    "logits = ff # calling the LOGS as logits \n",
    "counts = logits.exp() # the exp applied which are our counts, right!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f1b7dd1-2a0f-48a1-a146-eb80185ee865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1152, 0.0742, 0.0413, 0.0020, 0.0331, 0.0049, 0.0161, 0.0034, 0.0079,\n",
       "         0.0872, 0.0113, 0.0041, 0.0081, 0.0096, 0.0078, 0.0359, 0.0867, 0.0143,\n",
       "         0.0102, 0.0260, 0.0079, 0.0493, 0.0374, 0.0900, 0.0603, 0.0613, 0.0309,\n",
       "         0.0637],\n",
       "        [0.0045, 0.0861, 0.0808, 0.0235, 0.0047, 0.0474, 0.0483, 0.1689, 0.0231,\n",
       "         0.0251, 0.0099, 0.0181, 0.0088, 0.0045, 0.0071, 0.0132, 0.0132, 0.0050,\n",
       "         0.0032, 0.0253, 0.0619, 0.0128, 0.0450, 0.0453, 0.1312, 0.0089, 0.0583,\n",
       "         0.0159],\n",
       "        [0.0105, 0.0023, 0.0201, 0.0652, 0.0753, 0.0201, 0.0125, 0.0640, 0.0288,\n",
       "         0.0097, 0.0131, 0.0187, 0.0735, 0.0243, 0.0327, 0.0270, 0.0722, 0.0058,\n",
       "         0.0753, 0.0882, 0.0243, 0.0213, 0.0231, 0.0610, 0.0556, 0.0075, 0.0167,\n",
       "         0.0511],\n",
       "        [0.0105, 0.0023, 0.0201, 0.0652, 0.0753, 0.0201, 0.0125, 0.0640, 0.0288,\n",
       "         0.0097, 0.0131, 0.0187, 0.0735, 0.0243, 0.0327, 0.0270, 0.0722, 0.0058,\n",
       "         0.0753, 0.0882, 0.0243, 0.0213, 0.0231, 0.0610, 0.0556, 0.0075, 0.0167,\n",
       "         0.0511],\n",
       "        [0.0049, 0.0208, 0.0188, 0.0394, 0.0182, 0.1267, 0.0061, 0.0799, 0.0850,\n",
       "         0.0472, 0.1841, 0.0338, 0.0283, 0.0164, 0.0070, 0.0719, 0.0169, 0.0338,\n",
       "         0.0212, 0.0307, 0.0356, 0.0105, 0.0022, 0.0095, 0.0203, 0.0143, 0.0052,\n",
       "         0.0112]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The probability calculation ## \n",
    "prob = counts / counts.sum(1, keepdim=True)\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e005b6-94ad-4f7a-ac6e-9fe33089b514",
   "metadata": {},
   "source": [
    "üëâ Note: The process of `logits ‚Üí exp ‚Üí probability` is called the \"softmax\" activation! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b83815-72ae-4452-b93a-6af34e1b55ec",
   "metadata": {},
   "source": [
    "___\n",
    "> ‚ö† Numpy equivalent is the same: `np_array / np_array.sum(axis=1, keepdims=True)`\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67639c7e-05e4-48cc-a943-0d47ab37779f",
   "metadata": {},
   "source": [
    "## Now we have the distribution!\n",
    "Which we can use to predict the next character! **But of course** these are not tuned. And are **totally** dependent on the setting of the \"random weights\". \n",
    "\n",
    "We have 2 options:\n",
    "1. Keep changing the weights, use all numbers in the universe, try them out and check which random setting of weights are giving the least loss.\n",
    "2. Learn from the error and adapt the weights accordingly!\n",
    "\n",
    "Actually Karpathy gives a nice demonstration in this very clip, so please check that out there: [exact clip link](https://youtube.com/clip/UgkxVrO337xZPFmEc49wfPYN0mkD8vuCoDIk).\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/PaCmpygFfXo?clip=UgkxVrO337xZPFmEc49wfPYN0mkD8vuCoDIk&amp;clipt=ENy46AIYvI3sAg\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3771a277-40c0-44f8-aeb8-0651afd2f473",
   "metadata": {},
   "source": [
    "# ‚õè Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a81fb49-54b8-4675-80f7-e2dfad2d0206",
   "metadata": {},
   "source": [
    "## üëâ We need to understand \"how to calculate the loss\".\n",
    "So, in the last book we saw how that is done, we simply \"used the **probabilty**\" and converted that into the logits *(negative logits ‚Üí positive)* and that was the loss.\n",
    "\n",
    "Here, in the same hand, we will do the same.\n",
    "\n",
    "1. We have the correct labels\n",
    "2. We have the \"NN\" predicted next character\n",
    "3. So we will \"tally\" how much probability the NN has provided to our ***expected*** character.\n",
    "\n",
    "## üëâ At high-level\n",
    "1. We have provided `e` from the whole name \"emma\"\n",
    "2. For `e`, we did the encoding and feed into the NN\n",
    "3. The NN resulted the 28 logits\n",
    "4. We converted them into the probability. So now we have all characters' probabilities *(from `<`, `a`... to `z`, `>`)* for the character `e`)*.\n",
    "5. The expected next token is `m` so, there **should be** the highest probabilty to `m` after `e`.\n",
    "6. We will see what is the probability assigned by the NN to the token `m`.\n",
    "7. We will compare the expected from the real and calculate the loss\n",
    "8. Update the weights and re-iterate.\n",
    "\n",
    "___\n",
    "That's the high level view of the training. As shown above for the single example `emma`. But obviously we will do this for all names in the dataset ‚Äî which iteratively make the model to learn all the \"bigram\" relations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e11d86-c7aa-420d-9ffd-844f05d2ea74",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Forward pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11cd48eb-75fa-4da7-a060-1624193f6889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So, let's do that. Feeding in the `e` to the net\n",
    "### Starting afresh ###\n",
    "\n",
    "# Represents \"<emma\"\n",
    "xs_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47f314da-da36-488c-9999-b97263714ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 14, 14,  2,  1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Represents \"emma>\" ‚Äî not yet encoded and not required\n",
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23fba1fe-e4af-4cb4-b06a-2d3edb9343f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have the weights\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2be20f45-e888-4e63-b7fa-c6dd450ee7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 28])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The forward pass\n",
    "ff = xs_encoded @ W\n",
    "counts = ff.exp()\n",
    "prob = counts / counts.sum(1, keepdim=True)\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaeb2a0-915e-462e-b351-b5671ab28fd4",
   "metadata": {},
   "source": [
    "So when we put the `<` or the first character... the NN returned..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7587893c-491e-4f90-bdf5-9461ba63badd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1152, 0.0742, 0.0413, 0.0020, 0.0331, 0.0049, 0.0161, 0.0034, 0.0079,\n",
       "        0.0872, 0.0113, 0.0041, 0.0081, 0.0096, 0.0078, 0.0359, 0.0867, 0.0143,\n",
       "        0.0102, 0.0260, 0.0079, 0.0493, 0.0374, 0.0900, 0.0603, 0.0613, 0.0309,\n",
       "        0.0637], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d89036e-c353-4c67-b1ab-4b0f14069dd4",
   "metadata": {},
   "source": [
    "And that character is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f3ffefa-7c64-4a1f-9c9b-abbff88872f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1152, grad_fn=<MaxBackward1>), tensor(0))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prob[0].max(), prob[0].argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091921d3-eb1f-43ac-b903-b7f9dcb207f0",
   "metadata": {},
   "source": [
    "According to this *newborn-baby* network, the character `<` is **the most** probable character after the `<`. Whic of course is because of the randomly initialized weights.\n",
    "\n",
    "**But we expect** the character `e` after the `<` right? So... to \"index\" `e` we have the `ys` variable already!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9d07169-c1ba-45d2-abcb-24da8796102d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 14, 14,  2,  1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e, m, m, a, >\n",
    "ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8b5a9a-42bf-40bc-9746-f89837f141d2",
   "metadata": {},
   "source": [
    "So we need to check ***what is the probability assigned to the character at index `6` which represents `e`***?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58f5d0e6-f3a4-40f4-ae65-e5dfd24c573e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0161, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[0][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136659ff-5ae0-4697-b8b2-b31547e58dbe",
   "metadata": {},
   "source": [
    "Oops! That is just `1.6%`! <br>\n",
    "And even after that `<` we have the `e`, `m`, `m`, `a` all fed and have their individual probabilities. Let's see how that looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f243140b-5e1f-49eb-bcf4-8d460ed71369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0161, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0071, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0327, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0201, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0208, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# < ‚Üí e,   e ‚Üí m,       m ‚Üí m,      m ‚Üí a,     a ‚Üí >\n",
    "prob[0][6], prob[1][14], prob[2][14], prob[3][2], prob[4][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3459cc7-fb84-4eea-855f-f8ced8bc55cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0161, 0.0071, 0.0327, 0.0201, 0.0208], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More easily with \"indexing\"\n",
    "prob[[0, 1, 2, 3, 4], [6, 14, 14, 2, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d14a9c51-caf1-4358-8167-56f570dad1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0161, 0.0071, 0.0327, 0.0201, 0.0208], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dynamically\n",
    "prob[range(xs_encoded.shape[0]), ys]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd322a2e-89c2-4d65-99a0-75a707ea9907",
   "metadata": {},
   "source": [
    "And these above are the probs assigned to the **actual** tokens. And... fairly the model is giving poor probabilities to the expected tokens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "97cce6e3-0589-4e0b-bfb4-b722e06de440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.1312, 4.9411, 3.4207, 3.9048, 3.8742], grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = prob[range(xs_encoded.shape[0]), ys]\n",
    "loss = -loss.log()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9489f3ac-a521-4430-a6be-97fce16f35ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.0544, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss.mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcdbd8a-1b88-4acf-80e1-0d1a3e96e615",
   "metadata": {},
   "source": [
    "Alright, so on an average we have `4.0544` log-loss: which we need to optimize üòä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee24a0a9-b45a-48bb-8afc-c4e0e7bae4ac",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Backward pass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81ae07a-788b-4f1e-973f-8bf32617cb10",
   "metadata": {},
   "source": [
    "Setting all the gradients to be zero.\n",
    "\n",
    "> ‚Ñπ <br>*Of course, since this is the very first step, we haven't done any `backward` call yet, thus this `zero_grad` won't make difference in **this** first iteration, but as a part of this individual pieces of the dry run, we will keep this within our code so later we can include in the final code* ‚ò∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8f48915f-a2ff-4c1d-8ebd-c83b4bdcab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pytorch way of zero grad \n",
    "W.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4716fc-97b6-4e39-9258-9d170393dce5",
   "metadata": {},
   "source": [
    "> **Important**: If you don't know what and why are we doing this, and what this zero_grad is, then please refer the previous book ‚Üí section \"Bug 002\" for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fbb41b-b93e-4cce-957f-29754969a28f",
   "metadata": {},
   "source": [
    "Okay, some where **above** I said to **ignore** the `requires_grad` parameter when we were initializing the weights.\n",
    "```python\n",
    "W = torch.randn((28, 28), generator=generator, requires_grad=True)\n",
    "```\n",
    "\n",
    "We will keep this `true` so that the manual backpropogation is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37414351-5821-4a19-a5b9-d5ded8d9192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before backward\n",
    "W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20010374-5dc4-4dad-8cc2-65a8ae524abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.0544, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daa5d63-f4f9-4f2e-8a8b-0821d0f3aa36",
   "metadata": {},
   "source": [
    "Yo, we see? `grad_fn=<MeanBackward0>`? These **exactly** equivalent to what we did in the micrograd; i.e., for each operation we made a *local* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eb603102-f464-4d75-9cb1-a2a89b7b27db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MAGIC üéá\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f9eecf4-ef4d-466f-9911-1c44d21c01eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0230,  0.0148,  0.0083,  0.0004,  0.0066,  0.0010, -0.1968,  0.0007,\n",
       "          0.0016,  0.0174,  0.0023,  0.0008,  0.0016,  0.0019,  0.0016,  0.0072,\n",
       "          0.0173,  0.0029,  0.0020,  0.0052,  0.0016,  0.0099,  0.0075,  0.0180,\n",
       "          0.0121,  0.0123,  0.0062,  0.0127],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0010, -0.1958,  0.0038,  0.0079,  0.0036,  0.0253,  0.0012,  0.0160,\n",
       "          0.0170,  0.0094,  0.0368,  0.0068,  0.0057,  0.0033,  0.0014,  0.0144,\n",
       "          0.0034,  0.0068,  0.0042,  0.0061,  0.0071,  0.0021,  0.0004,  0.0019,\n",
       "          0.0041,  0.0029,  0.0010,  0.0022],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0009,  0.0172,  0.0162,  0.0047,  0.0009,  0.0095,  0.0097,  0.0338,\n",
       "          0.0046,  0.0050,  0.0020,  0.0036,  0.0018,  0.0009, -0.1986,  0.0026,\n",
       "          0.0026,  0.0010,  0.0006,  0.0051,  0.0124,  0.0026,  0.0090,  0.0091,\n",
       "          0.0262,  0.0018,  0.0117,  0.0032],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0042,  0.0009, -0.1919,  0.0261,  0.0301,  0.0081,  0.0050,  0.0256,\n",
       "          0.0115,  0.0039,  0.0052,  0.0075,  0.0294,  0.0097, -0.1869,  0.0108,\n",
       "          0.0289,  0.0023,  0.0301,  0.0353,  0.0097,  0.0085,  0.0093,  0.0244,\n",
       "          0.0222,  0.0030,  0.0067,  0.0205],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After backward\n",
    "W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "910efaa6-2d99-44f1-9978-779b2a29ce5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.grad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b8ec4d-8ebe-4f34-af13-c1691c30cfdc",
   "metadata": {},
   "source": [
    "We can see that **whole tensors** are filled with `0` zeros. These are where they haven't ever seen `1`. *(as `<emma` has only 4 unique characters, we can only see 4 tensors in W.grad with some non-zero grad.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703f2ee0-cb51-4c0b-a322-beac27152391",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Update "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "13f1aeb9-d066-4b05-98ee-0644e21d369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crazy update!\n",
    "learning_rate = 0.1\n",
    "W.data += -learning_rate * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6e657-dcb5-426a-952a-255f70fd9ea7",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Check loss!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9aebe0bd-bbfc-4bc3-acf8-70f738da1d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.0544, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before updation loss was...\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a6079b58-a755-4986-b6f9-e5850f938714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.0338, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The forward pass\n",
    "ff = xs_encoded @ W\n",
    "counts = ff.exp()\n",
    "prob = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "# After the update + forward pass the loss is...\n",
    "loss = -(prob[range(xs_encoded.shape[0]), ys].log()).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43851d09-3bee-4fae-be3a-9a484a64d717",
   "metadata": {},
   "source": [
    "Whooops! Slightly better! Indeed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0db718-fa17-4c7a-b968-8d131dfa2927",
   "metadata": {},
   "source": [
    "# The real training for multiple epochs!\n",
    "Consists of these steps:\n",
    "1. Forward pass\n",
    "2. Backward pass\n",
    "3. Update\n",
    "4. Repeat for number of epochs given\n",
    "\n",
    "That's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ad56933b-49c6-4fc3-912b-1240fe9de993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 4.0338\n",
      "Current loss: 4.0133\n",
      "Current loss: 3.9928\n",
      "Current loss: 3.9723\n",
      "Current loss: 3.9518\n",
      "Current loss: 3.9314\n",
      "Current loss: 3.911\n",
      "Current loss: 3.8907\n",
      "Current loss: 3.8703\n",
      "Current loss: 3.85\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for i in range(epochs):\n",
    "    # Step 1: The forward pass\n",
    "    ff = xs_encoded @ W\n",
    "    counts = ff.exp()\n",
    "    prob = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "    loss = -(prob[range(xs_encoded.shape[0]), ys].log()).mean()\n",
    "    print(\"Current loss:\", round(loss.item(), 4))\n",
    "    \n",
    "    # Step 2: Backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 3: Update\n",
    "    learning_rate = 0.1\n",
    "    W.data += -learning_rate * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac836be-0096-4185-b460-405e27fa61fb",
   "metadata": {},
   "source": [
    "Indeed! The loss is going down! We are rocking boyz üî•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559ad48b-66f4-474a-abda-3ac1cf844bf5",
   "metadata": {},
   "source": [
    "# ‚òÑ Training on whole dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8ad327f6-748e-48b6-96a1-f4186c52d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP - 1: CREATE A DATASET\n",
    "\n",
    "### For whole dataset \"note the `:`\" ###\n",
    "\n",
    "xs = [] # The ch1 (previous character)\n",
    "ys = [] # The ch2 (next character to be predicted - lables)\n",
    "\n",
    "for name in names[:]: # looking at the first example name only\n",
    "    name = \"<\" + name + \">\"\n",
    "    for ch1, ch2 in zip(name, name[1:]):    \n",
    "        xs.append(ch_to_number[ch1])\n",
    "        ys.append(ch_to_number[ch2])\n",
    "        \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "038cbb60-3cc5-4717-9b15-bcf700e0ccc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228146"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total characters\n",
    "len(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e555267c-7cc5-4607-8e00-80b085f46cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP - 2: ENCODE THE DATASET\n",
    "xs_encoded = torch.nn.functional.one_hot(xs, num_classes=28).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6ea5e1ec-1076-494c-b07f-d1a874b4eb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 28])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b190f83a-a45a-4894-9916-2d17b8e6d472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP - 3: INITIALIZE THE WEIGHTS\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "W = torch.randn((28, 28), generator=generator, requires_grad=True)\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b6fd9fcc-fe78-4c22-b2a3-9f7ffcd50df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 3.7839\n",
      "Current loss: 3.7831\n",
      "Current loss: 3.7822\n",
      "Current loss: 3.7814\n",
      "Current loss: 3.7806\n",
      "Current loss: 3.7797\n",
      "Current loss: 3.7789\n",
      "Current loss: 3.7781\n",
      "Current loss: 3.7773\n",
      "Current loss: 3.7764\n"
     ]
    }
   ],
   "source": [
    "# STEP - 4: RUN THE TRAINING LOOP\n",
    "epochs = 10\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    # Step 1: The forward pass\n",
    "    ff = xs_encoded @ W\n",
    "    counts = ff.exp()\n",
    "    prob = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "    loss = -(prob[range(xs_encoded.shape[0]), ys].log()).mean()\n",
    "    losses.append(loss)\n",
    "    print(\"Current loss:\", round(loss.item(), 4))\n",
    "    \n",
    "    # Step 2: Backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 3: Update\n",
    "    learning_rate = 0.1\n",
    "    W.data += -learning_rate * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08329400-b0ce-4cc4-a6b9-318882f5578e",
   "metadata": {},
   "source": [
    "Alright, from the start... we are having these losses. Okay! Let's run it through 100 epochs!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a610baf2-faff-45ec-84f7-67e806a5891c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 3.7756\n",
      "Current loss: 3.4146\n",
      "Current loss: 3.1954\n",
      "Current loss: 3.0538\n",
      "Current loss: 2.9535\n",
      "Current loss: 2.8796\n",
      "Current loss: 2.8241\n",
      "Current loss: 2.7812\n",
      "Current loss: 2.7469\n",
      "Current loss: 2.7187\n",
      "Current loss: 2.695\n",
      "Current loss: 2.6747\n",
      "Current loss: 2.6572\n",
      "Current loss: 2.6421\n",
      "Current loss: 2.6288\n",
      "Current loss: 2.6173\n",
      "Current loss: 2.6071\n",
      "Current loss: 2.5981\n",
      "Current loss: 2.5901\n",
      "Current loss: 2.583\n",
      "Current loss: 2.5766\n",
      "Current loss: 2.5708\n",
      "Current loss: 2.5655\n",
      "Current loss: 2.5607\n",
      "Current loss: 2.5563\n",
      "Current loss: 2.5522\n",
      "Current loss: 2.5484\n",
      "Current loss: 2.5449\n",
      "Current loss: 2.5416\n",
      "Current loss: 2.5386\n",
      "Current loss: 2.5357\n",
      "Current loss: 2.533\n",
      "Current loss: 2.5305\n",
      "Current loss: 2.5282\n",
      "Current loss: 2.526\n",
      "Current loss: 2.5239\n",
      "Current loss: 2.5219\n",
      "Current loss: 2.52\n",
      "Current loss: 2.5182\n",
      "Current loss: 2.5165\n",
      "Current loss: 2.5149\n",
      "Current loss: 2.5134\n",
      "Current loss: 2.512\n",
      "Current loss: 2.5106\n",
      "Current loss: 2.5093\n",
      "Current loss: 2.508\n",
      "Current loss: 2.5068\n",
      "Current loss: 2.5056\n",
      "Current loss: 2.5045\n",
      "Current loss: 2.5035\n",
      "Current loss: 2.5025\n",
      "Current loss: 2.5015\n",
      "Current loss: 2.5005\n",
      "Current loss: 2.4996\n",
      "Current loss: 2.4987\n",
      "Current loss: 2.4979\n",
      "Current loss: 2.4971\n",
      "Current loss: 2.4963\n",
      "Current loss: 2.4955\n",
      "Current loss: 2.4948\n",
      "Current loss: 2.4941\n",
      "Current loss: 2.4934\n",
      "Current loss: 2.4927\n",
      "Current loss: 2.4921\n",
      "Current loss: 2.4915\n",
      "Current loss: 2.4908\n",
      "Current loss: 2.4902\n",
      "Current loss: 2.4897\n",
      "Current loss: 2.4891\n",
      "Current loss: 2.4886\n",
      "Current loss: 2.488\n",
      "Current loss: 2.4875\n",
      "Current loss: 2.487\n",
      "Current loss: 2.4865\n",
      "Current loss: 2.486\n",
      "Current loss: 2.4856\n",
      "Current loss: 2.4851\n",
      "Current loss: 2.4847\n",
      "Current loss: 2.4842\n",
      "Current loss: 2.4838\n",
      "Current loss: 2.4834\n",
      "Current loss: 2.483\n",
      "Current loss: 2.4826\n",
      "Current loss: 2.4822\n",
      "Current loss: 2.4818\n",
      "Current loss: 2.4815\n",
      "Current loss: 2.4811\n",
      "Current loss: 2.4807\n",
      "Current loss: 2.4804\n",
      "Current loss: 2.4801\n",
      "Current loss: 2.4797\n",
      "Current loss: 2.4794\n",
      "Current loss: 2.4791\n",
      "Current loss: 2.4788\n",
      "Current loss: 2.4785\n",
      "Current loss: 2.4782\n",
      "Current loss: 2.4779\n",
      "Current loss: 2.4776\n",
      "Current loss: 2.4773\n",
      "Current loss: 2.4771\n"
     ]
    }
   ],
   "source": [
    "# Running for 100 epochs!\n",
    "epochs = 100\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    # Step 1: The forward pass\n",
    "    ff = xs_encoded @ W\n",
    "    counts = ff.exp()\n",
    "    prob = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "    loss = -(prob[range(xs_encoded.shape[0]), ys].log()).mean()\n",
    "    losses.append(loss)\n",
    "    print(\"Current loss:\", round(loss.item(), 4))\n",
    "    \n",
    "    # Step 2: Backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 3: Update\n",
    "    learning_rate = 50 # As in the lecture!\n",
    "    W.data += -learning_rate * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9585b5-ce73-4990-8c93-47d78e92ec5a",
   "metadata": {},
   "source": [
    "> So! In our previous attempt, we got `log_likelihood/n=2.455` loss - when there was the \"perfect\" relation was established (by counting). Here, by learning we achieve the same result!\n",
    "\n",
    "> üßß<br>***Note***: I've run the cell above multiple times. So to get the same loss, you should run that 100 epochs for around 4-5 times! And I think beyond `2.46` it will go down... but that is **not something** we should try. The learning rate is too high and keep running this more **might lead to worse loss.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa3213d-d29d-4618-acdb-20e18c42585b",
   "metadata": {},
   "source": [
    "# üòé Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06c5c96-071c-4a19-b246-efc3b6e83e01",
   "metadata": {},
   "source": [
    "## `1.` Generation with `tensor` seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "10b16c4a-bd9b-4d3f-9561-badb7e64aed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kann>', 'delle>', 'jp<ckwan>', 'riylen>', 'cama>']\n"
     ]
    }
   ],
   "source": [
    "generator = torch.Generator().manual_seed(42)\n",
    "new_names = []\n",
    "\n",
    "for i in range(5):\n",
    "    new_name = []\n",
    "    ch = \"<\"\n",
    "    ch_ix = ch_to_number[ch]\n",
    "    \n",
    "    while(ch != \">\"):\n",
    "        x_enc = torch.nn.functional.one_hot(torch.tensor(ch_ix), num_classes=28).float()\n",
    "        logits = x_enc @ W\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum()\n",
    "        \n",
    "        ch_ix = torch.multinomial(probs, num_samples=1, generator=generator).item()\n",
    "        ch = number_to_ch[ch_ix]\n",
    "        new_name.append(ch)\n",
    "    new_names.append(''.join(new_name))\n",
    "    \n",
    "print(new_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185eb4a-1334-4e42-b775-b9abfe722040",
   "metadata": {},
   "source": [
    "## `2.` Generation with `numpy` seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f723ed81-3869-47c6-bd78-ebe53913e3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['huria>', 'atin>', 'yn>', 'cahakan>', 'eigrali>']\n"
     ]
    }
   ],
   "source": [
    "seed = np.random.RandomState(42)\n",
    "new_names = []\n",
    "\n",
    "for i in range(5):\n",
    "    new_name = []\n",
    "    ch = \"<\"\n",
    "    ch_ix = ch_to_number[ch]\n",
    "    \n",
    "    while(ch != \">\"):\n",
    "        x_enc = torch.nn.functional.one_hot(torch.tensor(ch_ix, dtype=int), num_classes=28).float()\n",
    "        logits = x_enc @ W\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum()\n",
    "        \n",
    "        ch_ix = seed.choice(range(28), p=probs.detach().numpy())\n",
    "        ch = number_to_ch[ch_ix]\n",
    "        new_name.append(ch)\n",
    "        \n",
    "    new_names.append(''.join(new_name))\n",
    "\n",
    "print(new_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc469844-5c39-4870-8917-c676c39ccf1b",
   "metadata": {},
   "source": [
    "# Man!!\n",
    "Can you see? These `huria`, `atin` etc. are the ***exactly*** the same generation from our bigram!\n",
    "- The reason behind that working with numpy and not with tensor is `42` seed differs library to library\n",
    "- **That's why** I used numpy for generation here as well because in the previous notebook we use `42` seed for generation\n",
    "- This shows that the NN has **successfully** learnt the bigram table! That's impressive üòçü§ü"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ab486d-73c2-486e-a2bb-86f3f49c8ff8",
   "metadata": {},
   "source": [
    "## A small thing.\n",
    "While generating, **we may want to bias** our generation so that the model \"do not include\" the `<` character in the name as it did in the tensor. But for now, I think we are okay with the generation. The main aim was to learn how things work with \"deep learning\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c11f67-c041-4b52-9264-5ce85fe8bbd7",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a4c2c-9ae8-430e-bdb4-b06233568b9a",
   "metadata": {},
   "source": [
    "# Bonus üéâ\n",
    "Now, we will train the model but **with micrograd**! Get ready bois."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910e21ec-ad85-4b79-874a-13b5e558bcff",
   "metadata": {},
   "source": [
    "> **Please Note:** To avoid copy-pasting long classes of `Value`, `Neuron`, `Layer` and `MLP` from micrograd, I have made a seperate `micrograd.py` file from which we can import the classes to keep the code cleaner. Please find the same file in this folder itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbfbd40-6673-4bff-a0ad-aac6c2a2fbfa",
   "metadata": {},
   "source": [
    "Unfortunately, I wasn't able to complete this task for several reasons:\n",
    "- Micrograd doesn't support the vectorized operations, so many nested loops are required\n",
    "- Operations like log, exp, div also need to work through the vectorization layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f881aca-9568-4e91-bb3d-291dd77aa319",
   "metadata": {},
   "source": [
    "But still I have made the following code. Have also appended the comments for reading... but I would advise the reader **not to get lost** here. Thanks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ccd14f7a-8221-4006-ae29-9a1dbf12b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrograd import Value, Neuron, Layer, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "24e0e590-14c0-4cf8-a422-5617866a6947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 28])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The X\n",
    "xs_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "98cfafd2-4269-4e1e-a9b5-d09319f8c408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Y\n",
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f9c5b101-5297-4dfc-b910-0e0b00bf69d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(nin=28, nouts=[28]) # same structure as pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "dbf83b02-310c-46b8-a896-439cab237c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random weights\n",
    "len(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a5ca2a4f-358e-4e05-a2a1-a48769a486cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# W * nodes + bias\n",
    "(28 * 28) + 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "5b54aeb3-8155-42d1-8063-569326a663cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: tensor(3.2746)\n",
      "Current loss: tensor(3.2746)\n",
      "Current loss: tensor(3.2746)\n",
      "Current loss: tensor(3.2746)\n",
      "Current loss: tensor(3.2746)\n",
      "Current loss: tensor(3.2746)\n",
      "Current loss: tensor(3.2746)\n",
      "Current loss: tensor(3.2746)\n",
      "Current loss: tensor(3.2746)\n",
      "Current loss: tensor(3.2746)\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "losses = []\n",
    "for epoch in range(10):\n",
    "    # Forward pass\n",
    "    \n",
    "    # Simply predicting the distribution for next token from random weights\n",
    "    # SLOW SLOW SLOW -- DON'T TAKE WHOLE DATASET -- ONLY 5 CHARACTERS FOR NOW\n",
    "    preds = np.array([model(x) for x in xs_encoded[:5]])\n",
    "    \n",
    "    \n",
    "    PREDS = []\n",
    "    for example in preds:\n",
    "        EXAMPLE = []\n",
    "        for val in example:\n",
    "            VAL = val.exp()\n",
    "            EXAMPLE.append(VAL)\n",
    "        PREDS.append(EXAMPLE)\n",
    "    \n",
    "    # Now we have the predictions -> exp operation applied\n",
    "    COUNTS = np.array(PREDS)\n",
    "    \n",
    "    # Preparing for the probability conversion\n",
    "    SUM = []\n",
    "    for count in COUNTS:\n",
    "        SUM.append(count.sum())\n",
    "\n",
    "    # Converting into the probabilities\n",
    "    PROBS = []\n",
    "    for count_ary, sum_ in zip(COUNTS, SUM):\n",
    "        local_p = []\n",
    "        for count_elem in count_ary:\n",
    "            local_p.append(count_elem / sum_)\n",
    "        PROBS.append(local_p)\n",
    "    PROBS = np.array(PROBS)\n",
    "    \n",
    "    \n",
    "    # What the model has predicted for my word?\n",
    "    logs = []\n",
    "    for p_ in PROBS[range(5), ys[:5]]:\n",
    "        p_ = Value(-p_.log().data)\n",
    "        logs.append(p_)\n",
    "        \n",
    "    # Mean - loss\n",
    "    loss = sum(logs) / len(logs)\n",
    "    print(\"Current loss:\", loss.data)\n",
    "    \n",
    "    \n",
    "    ### ZERO GRAD ###\n",
    "    for p in model.parameters():\n",
    "        p.grad = 0.0\n",
    "        \n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    learning_rate = 50\n",
    "    for p in model.parameters():\n",
    "        # The weight update\n",
    "        p.data += -learning_rate * p.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed24401f-8501-45ff-9d08-1c93e8b371d8",
   "metadata": {},
   "source": [
    "Actually don't know why it is giving the same number... but yeah... I think some coding issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37700783-70ab-4fc2-859b-e53800eb12da",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d86084-3820-4221-898d-1b7dde57c99e",
   "metadata": {},
   "source": [
    "# Alright then!\n",
    "See you in the next lecture! We really are **generating** something!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
